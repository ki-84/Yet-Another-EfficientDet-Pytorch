{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49893a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imgnum= 13\n",
      "datasets/genzairyo/val/LINE_ALBUM_20211117_1_211118_73_jpg.rf.3d120167348e12a92fead904bd72a288.jpg\n",
      "datasets/genzairyo/val/LINE_ALBUM_20211117_1_211118_123_jpg.rf.f3e31464567d8e7b1a516f92b6dd03f1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26584/2455817307.py:88: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  (x1, y1, x2, y2) = out[i]['rois'][j].astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genzairyo\n",
      "0\n",
      "datasets/genzairyo/val/LINE_ALBUM_20211117_1_211118_243_jpg.rf.f3ab5e034ee87bf2ce71fd9abcb060d8.jpg\n",
      "genzairyo\n",
      "0\n",
      "datasets/genzairyo/val/LINE_ALBUM_20211117_1_211118_75_jpg.rf.390fcce8f712db73af0e11031fe2a4ff.jpg\n",
      "genzairyo\n",
      "0\n",
      "datasets/genzairyo/val/LINE_ALBUM_20211117_1_211118_298_jpg.rf.7c61f3ef8cd3020807d0204984306c3f.jpg\n",
      "genzairyo\n",
      "0\n",
      "datasets/genzairyo/val/LINE_ALBUM_20211117_1_211118_2_jpg.rf.e5d50b8251e984db49de51a13c4b5129.jpg\n",
      "datasets/genzairyo/val/LINE_ALBUM_20211117_1_211118_119_jpg.rf.88781804c765d1d5d29a818273a15492.jpg\n",
      "genzairyo\n",
      "0\n",
      "datasets/genzairyo/val/LINE_ALBUM_20211117_1_211118_56_jpg.rf.a67b01626c178427d66eae6571dc7882.jpg\n",
      "genzairyo\n",
      "0\n",
      "datasets/genzairyo/val/LINE_ALBUM_20211117_1_211118_266_jpg.rf.8229eddd157faa9878cfa1319ab72637.jpg\n",
      "datasets/genzairyo/val/LINE_ALBUM_20211117_1_211118_262_jpg.rf.9748b6742210e12b5c26556d4730ea0c.jpg\n",
      "genzairyo\n",
      "0\n",
      "datasets/genzairyo/val/LINE_ALBUM_20211117_1_211118_159_jpg.rf.2fac1cb48b5dfec7806771ca0167b189.jpg\n",
      "datasets/genzairyo/val/LINE_ALBUM_20211117_1_211118_183_jpg.rf.fe62c1600e11373d3c88fa8445b16658.jpg\n",
      "genzairyo\n",
      "0\n",
      "datasets/genzairyo/val/LINE_ALBUM_20211117_1_211118_149_jpg.rf.665104d10d92c5e7da58a0750514656a.jpg\n",
      "genzairyo\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.backends import cudnn\n",
    "\n",
    "from backbone import EfficientDetBackbone\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob \n",
    "import os\n",
    "from efficientdet.utils import BBoxTransform, ClipBoxes\n",
    "from utils.utils import preprocess, invert_affine, postprocess\n",
    "\n",
    "\n",
    "compound_coef = 0\n",
    "force_input_size = None  # set None to use default size\n",
    "#files = glob.glob(\"datasets/food_label/val_test/*.jpg\")\n",
    "files = glob.glob(\"datasets/genzairyo/val/*.jpg\")\n",
    "print(\"imgnum=\",len(files))\n",
    "for img_path in files:\n",
    "    print(img_path)\n",
    "\n",
    "\n",
    "\n",
    "    threshold = 0.5\n",
    "    iou_threshold = 0.1\n",
    "\n",
    "    use_cuda = True\n",
    "    use_float16 = False\n",
    "    cudnn.fastest = False\n",
    "    cudnn.benchmark = False\n",
    "\n",
    "    #obj_list = ['allergy','eiyou','object']\n",
    "    obj_list = ['genzairyo','object']\n",
    "    # tf bilinear interpolation is different from any other's, just make do\n",
    "    input_sizes = [512, 640, 768, 896, 1024, 1280, 1280, 1536]\n",
    "    input_size = input_sizes[compound_coef] if force_input_size is None else force_input_size\n",
    "    ori_imgs, framed_imgs, framed_metas = preprocess(img_path, max_size=input_size)\n",
    "    full_size_image = cv2.imread(img_path)\n",
    "\n",
    "    if use_cuda:\n",
    "        x = torch.stack([torch.from_numpy(fi).cuda() for fi in framed_imgs], 0)\n",
    "    else:\n",
    "        x = torch.stack([torch.from_numpy(fi) for fi in framed_imgs], 0)\n",
    "\n",
    "    x = x.to(torch.float32 if not use_float16 else torch.float16).permute(0, 3, 1, 2)\n",
    "\n",
    "    model = EfficientDetBackbone(compound_coef=compound_coef, num_classes=len(obj_list),\n",
    "\n",
    "                                 # replace this part with your project's anchor config\n",
    "                                 ratios=[(1.0, 1.0), (1.3, 0.8), (1.9, 0.5)],\n",
    "                                 scales=[2 ** 0, 2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)])\n",
    "\n",
    "    model.load_state_dict(torch.load('logs/genzairyo/efficientdet-d0_268_10207.pth'))\n",
    "    model.requires_grad_(False)\n",
    "    model.eval()\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "    if use_float16:\n",
    "        model = model.half()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        features, regression, classification, anchors = model(x)\n",
    "\n",
    "        regressBoxes = BBoxTransform()\n",
    "        clipBoxes = ClipBoxes()\n",
    "\n",
    "        out = postprocess(x,\n",
    "                          anchors, regression, classification,\n",
    "                          regressBoxes, clipBoxes,\n",
    "                          threshold, iou_threshold)\n",
    "\n",
    "\n",
    "    out = invert_affine(framed_metas, out)\n",
    "    #print(\"out\",out)\n",
    "    #print(\"x\",x)\n",
    "    #plt.imshow(ori_imgs[0])\n",
    "    #print(\"len_imgs\",len(ori_imgs))\n",
    "    \n",
    "    for i in range(len(ori_imgs)):\n",
    "        #print(\"len_out\",len(out[i]['rois']))\n",
    "        if len(out[i]['rois']) == 0:\n",
    "            cv2.imwrite(\"res/res_th_\"+str(threshold)+\"_\"+os.path.basename(img_path),ori_imgs[i])\n",
    "            continue\n",
    "        ori_imgs[i] = ori_imgs[i].copy()\n",
    "\n",
    "        for j in range(len(out[i]['rois'])):\n",
    "            (x1, y1, x2, y2) = out[i]['rois'][j].astype(np.int)\n",
    "            #print(\"out\",out[i]['rois'][j].astype(np.int))\n",
    "            obj = obj_list[out[i]['class_ids'][j]]\n",
    "            \n",
    "            cv2.rectangle(ori_imgs[i], (x1, y1), (x2, y2), (255*obj_list.index(obj), 128, 64), 2)\n",
    "            crop_img = full_size_image[y1:y2, x1:x2]\n",
    "            cv2.imwrite(\"res/res_crop_\"+obj+\"_\"+str(j)+\"_\"+os.path.basename(img_path),crop_img)\n",
    "            \n",
    "            #result = reader.readtext(crop_img, detail=0)\n",
    "            \n",
    "            score = float(out[i]['scores'][j])\n",
    "            print(obj)\n",
    "            print(obj_list.index(obj))\n",
    "\n",
    "            cv2.putText(ori_imgs[i], '{}, {:.3f}'.format(obj, score),\n",
    "                        (x1, y1 + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8,\n",
    "                        (255*obj_list.index(obj), 128, 64), 2)\n",
    "            cv2.imwrite(\"res/res_th_\"+str(threshold)+\"_\"+os.path.basename(img_path),ori_imgs[i])\n",
    "    \n",
    "\n",
    "            #plt.imshow(ori_imgs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40ebcb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7b8cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea460bee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7708d29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc918ce6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75647c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
